---
title: "14：スロットリング"
---

## 問題点

レート制限（スロットリング）とは、一定の制約を超える操作の頻度を抑えることを言います。大規模なシステムでは、レート制限は通常は下層のサービスやリソースを保護するために使用します。レート制限は一般的にサービスの保護手段として実施します。共有サービスは意図したものであれ意図しないものであれ過度な使用から自身を保護して、サービスの可用性を維持する必要があります。高度に拡張可能なシステムですら、あるレベルにおいては消費に制限をかけるべきです。システムに高い性能を発揮させるには、**障害の連鎖** の可能性を減らすためにクライアントもレート制限を考慮して設計しなければなりません。クライアント側とサーバー側の両方でのレート制限は、大規模な分散型システムの全域にわたるスループットの最大化と、エンドツーエンドのレイテンシーの最小化にとって極めて重要です。

このチュートリアルでは、プロキシサービスにレート制限機能を実装します。

## フィルター

Pipyのビルトインフィルター[throttleMessageRate](/reference/api/Configuration/throttleMessageRate)と[throttleDataRate](/reference/api/Configuration/throttleDataRate)を使用してレート制限を実装します。ここで前者は1秒あたりの最大リクエスト数の、後者は1秒あたりの最大バイト数の制限に使用します。 どちらもよく似たパラメーターのセットを持っています。

* *quota* ：割り当てを表し、タイプは数値、文字列、関数です。
* *account* ：割り当て単位/精度のレベルです。タイプは文字列か関数です。サービス名、リクエストパス、リクエストヘッダー、その他の要素などの複雑な組み合わせとなります。

## 設定

このチュートリアルでは、`service-hi` にレート制限を実装し、制限をサービスレベルで稼働させます。

``` js
//throtlle.json
{
  "services": {
    "service-hi": {
      "rateLimit": 1000
    }
  }
}
```

## コードの説明

設定はJSONマップオブジェクトで定義したため、それを直接ここにインポートできます。`router` モジュールからサービス名を取得するには、エクスポートした変数 `__serviceID` をインポートする必要があります。

``` js
pipy({
  _services: config.services,
  _rateLimit: undefined,
})

.import({
  __serviceID: 'router',
})
```

次のステップではリクエストを処理します。リクエストしたサービス用にレート制限が設定されていなかった場合、そのリクエストをバイパスします。

``` js
.pipeline('request')
  .handleStreamStart(
    () => _rateLimit = _services[__serviceID]?.rateLimit
  )
  .link(
    'throttle', () => Boolean(_rateLimit),
    'bypass'
  )
```

前述のとおり、サービスのリクエスト数に最大の割り当てを設定しているので、 *account* は直接サービス名を使用します。

``` js
.pipeline('throttle')
  .throttleMessageRate(
    () => _rateLimit,
    () => __serviceID,
  )

.pipeline('bypass')
```

また、忘れずにプラグインのコード の `use` の部分を調整し、禁止リストを削除していることを確認してください。そうしないとレート制限サービスが適切に作動しません。

## テストしてみる

*wrk* ツールを使ってリクエストの同時発生をシミュレートします。

``` shell
wrk -c10 -t10 -d 30s http://localhost:8000/hi
Running 30s test @ http://localhost:8000/hi
  10 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   214.40ms  288.77ms 931.19ms   79.06%
    Req/Sec   327.77    356.74     1.00k    77.05%
  30000 requests in 30.08s, 2.60MB read
Requests/sec:    997.35
Transfer/sec:     88.63KB
```

注記：テストを長く続けるほど、結果は設定に近づきます。アップストリームの処理時間が非常に短いため、例えば私のラップトップPCでは、ローカル環境で16,000/sに到達できます。テスト時間が短い場合、差異は比較的大きくなります。

## まとめ

これはレート制限の非常にシンプルな実装にすぎず、サービスの最大キャパシティを設定してそれを達成しています。この達成度は変動することがあり、場合によってはサービスの各パスのキャパシティが変動します。例えばあるサービスは直接メモリーから読み出し、他のサービスは別のサービスを呼ぶ必要があり、また別のサービスはデータベースを読み書きする必要がある場合などです。よって実際の実装は、要件がシンプルか複雑なのかに応じて行います。

### 要点
* スロットリングには2種類のフィルター、`throttleMessageRate` と `throttleDataRate` を使用します。
* 現在の制限機能の精度は、フィルターの *account* パラメーターで柔軟に対応できます。

### 次のパートの内容

現在の制限を使用してアップストリームの負荷を制御できます。実はキャッシュするのがもっと普通の方法です。一部のレスポンスはプロキシがキャッシュし、一定時間のうちにそのレスポンスはキャッシュから直接取得されるので、ネットワークとアップストリームサービスの負荷が軽減されます。

次のチュートリアルでは、プロキシサーバーにキャッシュ機能を追加します。

